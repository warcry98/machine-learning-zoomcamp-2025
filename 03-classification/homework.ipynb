{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4835781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1462, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income employment_status       location  \\\n",
       "0      paid_ads         NaN                         1        79450.0        unemployed  south_america   \n",
       "1  social_media      retail                         1        46992.0          employed  south_america   \n",
       "2        events  healthcare                         5        78796.0        unemployed      australia   \n",
       "3      paid_ads      retail                         2        83843.0               NaN      australia   \n",
       "4      referral   education                         3        85012.0     self_employed         europe   \n",
       "\n",
       "   interaction_count  lead_score  converted  \n",
       "0                  4        0.94          1  \n",
       "1                  1        0.80          0  \n",
       "2                  3        0.69          1  \n",
       "3                  1        0.87          0  \n",
       "4                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ac67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column (top 10):\n",
      "annual_income               181\n",
      "industry                    134\n",
      "lead_source                 128\n",
      "employment_status           100\n",
      "location                     63\n",
      "number_of_courses_viewed      0\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n",
      "Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "target_col = \"converted\"\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "cat_cols = [c for c in feature_cols if df[c].dtype == \"object\"]\n",
    "num_cols = [c for c in feature_cols if df[c].dtype != \"object\"]\n",
    "\n",
    "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column (top 10):\")\n",
    "print(missing_counts.head(10))\n",
    "\n",
    "df[cat_cols] = df[cat_cols].fillna(\"NA\")\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "\n",
    "assert df[cat_cols].isna().sum().sum() == 0, \"Still have NA in categorical\"\n",
    "assert df[num_cols].isna().sum().sum() == 0, \"Still have NA in numerical\"\n",
    "print(\"Missing values handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3535f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - Most frequent `industry`: retail\n"
     ]
    }
   ],
   "source": [
    "mode_industry = df['industry'].mode(dropna=False)[0]\n",
    "print(\"Q1 - Most frequent `industry`:\", mode_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "279a6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair correlations:\n",
      "interaction_count & lead_score: 0.0099\n",
      "number_of_courses_viewed & lead_score: -0.0049\n",
      "number_of_courses_viewed & interaction_count: -0.0236\n",
      "annual_income & interaction_count: 0.0270\n",
      "\n",
      "Q2 - Biggest correlation pair: ('annual_income', 'interaction_count') with corr = 0.027\n"
     ]
    }
   ],
   "source": [
    "num_df = df[num_cols].copy()\n",
    "corr = num_df.corr()\n",
    "\n",
    "pairs = [\n",
    "    (\"interaction_count\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"interaction_count\"),\n",
    "    (\"annual_income\", \"interaction_count\"),\n",
    "]\n",
    "\n",
    "pair_corrs = {}\n",
    "for a, b in pairs:\n",
    "    if a in num_df.columns and b in num_df.columns:\n",
    "        pair_corrs[(a, b)] = corr.loc[a, b]\n",
    "    else:\n",
    "        pair_corrs[(a, b)] = np.nan\n",
    "\n",
    "print(\"Pair correlations:\")\n",
    "for k, v in pair_corrs.items():\n",
    "    print(f\"{k[0]} & {k[1]}: {v:.4f}\" if pd.notna(v) else f\"{k[0]} & {k[1]}: N/A\")\n",
    "\n",
    "# Identify max absolute correlation among given pairs (ignoring NaN)\n",
    "valid_items = [(k, v) for k, v in pair_corrs.items() if pd.notna(v)]\n",
    "best_pair, best_val = max(valid_items, key=lambda kv: abs(kv[1]))\n",
    "print(\"\\nQ2 - Biggest correlation pair:\", best_pair, \"with corr =\", round(best_val, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb47f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "Train: (877, 8) Val: (292, 8) Test: (293, 8)\n",
      "Target balance (train): 0.6191562143671607\n"
     ]
    }
   ],
   "source": [
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].astype(int).values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "print(\"Target balance (train):\", np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06972c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information (rounded to 2 decimals) for selected vars:\n",
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.03\n",
      "employment_status: 0.01\n",
      "\n",
      "Q3 - Variable(s) with biggest MI: ['lead_source'] with score 0.03\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = X_train[cat_cols].copy()\n",
    "\n",
    "encoders = {}\n",
    "X_train_cat_enc = pd.DataFrame(index=X_train_cat.index)\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train_cat_enc[c] = le.fit_transform(X_train_cat[c])\n",
    "    encoders[c] = le\n",
    "\n",
    "mi_scores = mutual_info_classif(\n",
    "    X_train_cat_enc.values, y_train, discrete_features=True, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "mi_by_col = {col: score for col, score in zip(cat_cols, mi_scores)}\n",
    "\n",
    "options_q3 = [\"industry\", \"location\", \"lead_source\", \"employment_status\"]\n",
    "filtered_mi = {k: round(mi_by_col.get(k, np.nan), 2) for k in options_q3}\n",
    "\n",
    "print(\"Mutual Information (rounded to 2 decimals) for selected vars:\")\n",
    "for k in options_q3:\n",
    "    print(f\"{k}: {filtered_mi[k]}\")\n",
    "\n",
    "max_mi = np.nanmax(list(filtered_mi.values()))\n",
    "best_vars = [k for k, v in filtered_mi.items() if v == max_mi]\n",
    "print(\"\\nQ3 - Variable(s) with biggest MI:\", best_vars, \"with score\", max_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a17689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 - Validation Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "numeric_features = num_cols\n",
    "categorical_features = cat_cols\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    solver=\"liblinear\", C=1.0, max_iter=1000, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", logreg)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Q4 - Validation Accuracy:\", round(val_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc8ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline val accuracy (all features): 0.6815\n",
      "Accuracy differences (baseline - without feature):\n",
      "industry: -0.0068\n",
      "employment_status: 0.0\n",
      "lead_score: 0.0068\n",
      "\n",
      "Q5 - Feature with smallest difference: industry  (diff = -0.0068 )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_acc = accuracy_score(y_val, pipe.predict(X_val))\n",
    "\n",
    "features_to_test = [\"industry\", \"employment_status\", \"lead_score\"]\n",
    "diffs = {}\n",
    "\n",
    "for feat in features_to_test:\n",
    "    reduced_num = [c for c in numeric_features if c != feat]\n",
    "    reduced_cat = [c for c in categorical_features if c != feat]\n",
    "\n",
    "    preprocess_reduced = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", reduced_num),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), reduced_cat),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_reduced = Pipeline(steps=[(\"preprocess\", preprocess_reduced), (\"model\", logreg)])\n",
    "    pipe_reduced.fit(X_train, y_train)\n",
    "    acc_reduced = accuracy_score(y_val, pipe_reduced.predict(X_val))\n",
    "    diffs[feat] = baseline_acc - acc_reduced\n",
    "\n",
    "print(\"Baseline val accuracy (all features):\", round(baseline_acc, 4))\n",
    "print(\"Accuracy differences (baseline - without feature):\")\n",
    "for k, v in diffs.items():\n",
    "    print(f\"{k}: {round(v, 4)}\")\n",
    "\n",
    "min_feat = min(diffs, key=lambda k: diffs[k])\n",
    "print(\"\\nQ5 - Feature with smallest difference:\", min_feat, \" (diff =\", round(diffs[min_feat], 4), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72f3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C grid results (rounded to 3 decimals):\n",
      "C=0.01: 0.688\n",
      "C=0.1: 0.682\n",
      "C=1: 0.682\n",
      "C=10: 0.682\n",
      "C=100: 0.682\n",
      "\n",
      "Q6 - Best C on validation set: 0.01 (accuracy = 0.688)\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "results = []\n",
    "\n",
    "for C in Cs:\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=C, max_iter=1000, random_state=RANDOM_STATE)\n",
    "    pipeC = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipeC.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_val, pipeC.predict(X_val))\n",
    "    results.append((C, acc))\n",
    "\n",
    "print(\"C grid results (rounded to 3 decimals):\")\n",
    "for C, acc in results:\n",
    "    print(f\"C={C}: {round(acc, 3)}\")\n",
    "\n",
    "best_acc = max(acc for _, acc in results)\n",
    "best_candidates = [C for C, acc in results if acc == best_acc]\n",
    "best_C = min(best_candidates)\n",
    "\n",
    "print(f\"\\nQ6 - Best C on validation set: {best_C} (accuracy = {round(best_acc, 3)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
